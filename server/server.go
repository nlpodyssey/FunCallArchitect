// Copyright 2024 The NLP Odyssey Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package server

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sync"

	"github.com/nlpodyssey/funcallarchitect/agent"
	"github.com/nlpodyssey/funcallarchitect/progress"
)

type SSEProgressStream struct {
	ch chan<- string
}

func NewSSEProgressStream(ch chan<- string) *SSEProgressStream {
	return &SSEProgressStream{ch: ch}
}

func (se *SSEProgressStream) Send(event string) {
	se.ch <- event
}

type Server struct {
	Agent *agent.Agent
	mu    sync.Mutex
}

func NewServer(a *agent.Agent) *Server {
	return &Server{Agent: a}
}

func (a *Server) HandleRESTRequest(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var request struct {
		Message string `json:"message"`
	}

	if err := json.NewDecoder(r.Body).Decode(&request); err != nil {
		http.Error(w, "Invalid request body", http.StatusBadRequest)
		return
	}

	ctx, cancel := context.WithCancel(r.Context())
	defer cancel()

	data, err := postprocessExecutionForREST(a.Agent.Process(ctx, request.Message, &progress.NoOp{}))
	if err != nil {
		http.Error(w, fmt.Sprintf("Error processing request: %v", err), http.StatusInternalServerError)
		return
	}

	response := struct {
		Output string `json:"output"`
	}{
		Output: data.Output,
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(response)
}

func postprocessExecutionForREST(execution *agent.ProcessingResult, err error) (Data, error) {
	if err != nil {
		return Data{}, fmt.Errorf("error processing query: %w", err)
	}
	results := execution.Execution.MainFuncResults()

	output, err := results.Format("")
	if err != nil {
		return Data{}, fmt.Errorf("error formatting results: %v", err)
	}

	return Data{
		Output: output,
	}, nil
}

func (a *Server) HandleUserRequest(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "text/event-stream")
	w.Header().Set("Cache-Control", "no-cache")
	w.Header().Set("Connection", "keep-alive")
	w.Header().Set("Access-Control-Allow-Origin", "*")

	flusher, ok := w.(http.Flusher)
	if !ok {
		http.Error(w, "Streaming unsupported", http.StatusInternalServerError)
		return
	}

	body, err := io.ReadAll(r.Body)
	if err != nil {
		http.Error(w, "Failed to read request body", http.StatusBadRequest)
		return
	}
	message := string(body)

	ctx, cancel := context.WithCancel(r.Context())
	defer cancel()

	logCh := make(chan string)
	progressStream := NewSSEProgressStream(logCh)

	go func() {
		defer close(logCh)

		data, err := postprocessExecution(a.Agent.Process(ctx, message, progressStream))
		if err != nil {
			a.sendSSEEvent(w, flusher, "error", map[string]any{"message": err.Error()})
			return
		}

		jsonData, err := json.Marshal(data)
		if err != nil {
			a.sendSSEEvent(w, flusher, "error", map[string]any{"message": err.Error()})
			return
		}

		var result map[string]interface{}
		_ = json.Unmarshal(jsonData, &result)

		a.sendSSEEvent(w, flusher, "result", map[string]any{"message": result})
	}()

	for {
		select {
		case <-ctx.Done():
			return
		case logMsg, ok := <-logCh:
			if !ok {
				logCh = nil
			} else {
				a.sendSSEEvent(w, flusher, "log", map[string]any{"message": logMsg})
			}
		}

		if logCh == nil {
			break
		}
	}
}

func (a *Server) sendSSEEvent(w http.ResponseWriter, flusher http.Flusher, event string, data map[string]any) {
	a.mu.Lock()
	defer a.mu.Unlock()

	jsonData, err := json.Marshal(data)
	if err != nil {
		fmt.Fprintf(w, "event: error\ndata: %s\n\n", err.Error())
		flusher.Flush()
		return
	}

	fmt.Fprintf(w, "event: %s\n", event)
	fmt.Fprintf(w, "data: %s\n\n", jsonData)
	flusher.Flush()
}

func (a *Server) Start(port int) error {
	http.HandleFunc("/process", a.HandleUserRequest)
	return http.ListenAndServe(fmt.Sprintf(":%d", port), nil)
}

// Data represents the output and associated information from an LLM agent's execution.
type Data struct {
	// Output contains the primary textual response generated by the LLM agent.
	Output string `json:"output"`

	// FuncCalls represents a string-encoded list or description of the functions
	// that were called during the agent's execution.
	FuncCalls string `json:"func_calls"`
}

func postprocessExecution(result *agent.ProcessingResult, err error) (Data, error) {
	if err != nil {
		return Data{}, fmt.Errorf("error processing query: %w", err)
	}
	results := result.Execution.MainFuncResults()

	output, err := results.Format("")
	if err != nil {
		return Data{}, fmt.Errorf("error formatting results: %v", err)
	}

	funcCalls, err := json.MarshalIndent(result.Execution.FuncCalls, "", "  ")
	if err != nil {
		return Data{}, fmt.Errorf("error marshaling func calls: %v", err)
	}

	return Data{
		Output:    output,
		FuncCalls: string(funcCalls),
	}, nil
}
