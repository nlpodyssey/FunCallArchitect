// Copyright 2024 The NLP Odyssey Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package main

import (
	"context"
	"encoding/json"
	"flag"
	"fmt"
	"log"
	"os"
	"time"

	"github.com/joho/godotenv"
	"github.com/nlpodyssey/funcallarchitect/agent"
	"github.com/nlpodyssey/funcallarchitect/handler"
	"github.com/nlpodyssey/funcallarchitect/llamacpp"
	"github.com/nlpodyssey/funcallarchitect/server"
)

const (
	defaultServerPort = 8080
	defaultQuery      = "What's the weather like in Turin?"
)

type config struct {
	ServerMode bool
	Port       int
	Query      string
	LLMConfig  llamacpp.Config
}

func main() {
	if err := run(); err != nil {
		log.Fatalf("Error: %v", err)
	}
}

func run() error {
	if err := godotenv.Load(); err != nil {
		log.Println("No .env file found or error loading it. Using environment variables.")
	}

	cfg, err := parseConfig()
	if err != nil {
		return fmt.Errorf("parsing config: %w", err)
	}

	a, err := setupAgent(cfg)
	if err != nil {
		return fmt.Errorf("setting up agent: %w", err)
	}

	if cfg.ServerMode {
		return runServer(a, cfg.Port)
	}

	return runDirectQuery(a, cfg.Query)
}

func parseConfig() (config, error) {
	cfg := config{}

	flag.BoolVar(&cfg.ServerMode, "server", false, "Run in server mode")
	flag.IntVar(&cfg.Port, "port", defaultServerPort, "Port to run the server on (only used in server mode)")
	flag.StringVar(&cfg.Query, "query", "", "Query for direct mode (if not provided, will use a default query)")
	flag.Parse()

	if !cfg.ServerMode && cfg.Query == "" {
		cfg.Query = defaultQuery
		fmt.Println("No query provided. Using default query:", cfg.Query)
	}

	cfg.LLMConfig = llamacpp.Config{
		APIKey:      getEnv("LLM_API_KEY", ""),
		Model:       getEnv("LLM_MODEL", ""),
		Endpoint:    getEnv("LLM_ENDPOINT", ""),
		Temperature: 0.0,
		TopP:        0.001,
		MaxTokens:   5000,
		Timeout:     60 * time.Second,
		UseGrammar:  true,
	}

	return cfg, validateConfig(cfg)
}

func validateConfig(cfg config) error {
	if cfg.LLMConfig.Endpoint == "" {
		return fmt.Errorf("LLM_ENDPOINT must be set")
	}
	if cfg.LLMConfig.APIKey == "" {
		log.Println("Warning: LLM_API_KEY is not set")
	}
	if cfg.LLMConfig.Model == "" {
		log.Println("Warning: LLM_MODEL is not set")
	}
	return nil
}

func setupAgent(cfg config) (*agent.Agent, error) {
	completionClient := llamacpp.NewClient(cfg.LLMConfig)

	return agent.NewAgent(handler.RequestHandlerConfig{
		LLMClient:            completionClient,
		Tools:                &Tools{},
		Timeout:              60 * time.Second,
		EnableConcurrentExec: true,
	})
}

func runServer(a *agent.Agent, port int) error {
	fmt.Printf("Starting server on port %d\n", port)
	return server.NewServer(a).Start(port)
}

// Data represents the output and associated information from an LLM agent's execution.
type Data struct {
	// Output contains the primary textual response generated by the LLM agent.
	Output string `json:"output"`

	// FuncCalls represents a string-encoded list or description of the functions
	// that were called during the agent's execution.
	FuncCalls string `json:"func_calls"`
}

func postprocessExecution(result *agent.ProcessingResult, err error) (Data, error) {
	if err != nil {
		return Data{}, fmt.Errorf("error processing query: %w", err)
	}
	results := result.Execution.MainFuncResults()

	output, err := results.Format("")
	if err != nil {
		return Data{}, fmt.Errorf("error formatting results: %v", err)
	}

	funcCalls, err := json.MarshalIndent(result.Execution.FuncCalls, "", "  ")
	if err != nil {
		return Data{}, fmt.Errorf("error marshaling func calls: %v", err)
	}

	return Data{
		Output:    output,
		FuncCalls: string(funcCalls),
	}, nil
}

func runDirectQuery(a *agent.Agent, query string) error {
	fmt.Println("Running direct query:", query)
	result, err := postprocessExecution(a.Process(context.Background(), query, &PrintEmitter{}))
	if err != nil {
		return fmt.Errorf("processing query: %w", err)
	}

	fmt.Printf("# FuncCalls\n%s\n", result.FuncCalls)
	fmt.Printf("# Output:\n%s\n", result.Output)
	return nil
}

type PrintEmitter struct{}

func (ne *PrintEmitter) Send(event string) {
	fmt.Println(event)
}

func getEnv(key, fallback string) string {
	if value, exists := os.LookupEnv(key); exists {
		return value
	}
	return fallback
}
